{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas and numpy package.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>general_health</th>\n",
       "      <th>physical_health_days</th>\n",
       "      <th>mental_health_days</th>\n",
       "      <th>has_health_plan</th>\n",
       "      <th>meets_aerobic_guidelines</th>\n",
       "      <th>physical_activity_150min</th>\n",
       "      <th>muscle_strengthening</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>high_cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>height_inches</th>\n",
       "      <th>bmi</th>\n",
       "      <th>education_level</th>\n",
       "      <th>income_group</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_consumption</th>\n",
       "      <th>binge_drinking</th>\n",
       "      <th>heavy_drinking</th>\n",
       "      <th>diabetes_status</th>\n",
       "      <th>difficulty_walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>25.85</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>33.47</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>22.96</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>41.84</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>29.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  general_health  physical_health_days  mental_health_days  \\\n",
       "0           4             4.0                   0.0                 0.0   \n",
       "1           8             3.0                   5.0                 0.0   \n",
       "2           9             3.0                   0.0                 0.0   \n",
       "3          10             3.0                   0.0                 0.0   \n",
       "4          12             2.0                   0.0                 0.0   \n",
       "\n",
       "   has_health_plan  meets_aerobic_guidelines  physical_activity_150min  \\\n",
       "0              1.0                       1.0                       1.0   \n",
       "1              1.0                       0.0                       3.0   \n",
       "2              1.0                       1.0                       1.0   \n",
       "3              1.0                       1.0                       1.0   \n",
       "4              1.0                       1.0                       1.0   \n",
       "\n",
       "   muscle_strengthening  high_blood_pressure  high_cholesterol  ...  \\\n",
       "0                   0.0                  0.0               1.0  ...   \n",
       "1                   0.0                  0.0               0.0  ...   \n",
       "2                   0.0                  0.0               0.0  ...   \n",
       "3                   1.0                  0.0               0.0  ...   \n",
       "4                   0.0                  1.0               1.0  ...   \n",
       "\n",
       "   height_inches    bmi  education_level  income_group  smoking_status  \\\n",
       "0           68.0  25.85              3.0           5.0             4.0   \n",
       "1           64.0  33.47              3.0           4.0             4.0   \n",
       "2           70.0  22.96              2.0           5.0             3.0   \n",
       "3           71.0  41.84              3.0           5.0             4.0   \n",
       "4           68.0  29.65              4.0           6.0             3.0   \n",
       "\n",
       "   alcohol_consumption  binge_drinking  heavy_drinking  diabetes_status  \\\n",
       "0                  1.0             1.0             1.0              1.0   \n",
       "1                  0.0             1.0             1.0              3.0   \n",
       "2                  0.0             1.0             1.0              1.0   \n",
       "3                  0.0             1.0             1.0              3.0   \n",
       "4                  1.0             1.0             1.0              3.0   \n",
       "\n",
       "   difficulty_walking  \n",
       "0                 1.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 1.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the data set.\n",
    "df = pd.read_csv('df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting unnecessary column and making all non diabetic entries being represented by 0.\n",
    "del df['Unnamed: 0']\n",
    "df['diabetes_status'] = df['diabetes_status'].replace(3,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What scoring metric should be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four metrics that I will consider and discuss:\n",
    "\n",
    "1. Accuracy\n",
    "2. Precision\n",
    "3. Recall\n",
    "4. F<sub>1</sub> score\n",
    "\n",
    "* Accuracy is the number of correct predictions divided by the total number of predictions. However, accuracy combines predictions for both classes, so it does not indicate whether the model performs better on one class than the other. In this scenario, especially with an imbalanced target variable, accuracy may be misleading, as it can be negatively affected if the model performs poorly on one class.\n",
    "\n",
    "The other three metrics—precision, recall, and F<sub>1</sub> score—are class-dependent. In other words, they require specifying the positive label. Since the main objective of this project is to predict whether an individual is diabetic, we will define our positive label as 1 (representing diabetic individuals).\n",
    "\n",
    "* Precision is the number of true positives (correctly predicted diabetic individuals) divided by the sum of true positives and false positives (incorrectly predicted diabetic individuals) (Precision_Score, n.d.).\n",
    "\n",
    "* Recall is the number of true positives divided by the sum of true positives and false negatives (where diabetic individuals are incorrectly predicted as non-diabetic) (Recall_Score, n.d.).\n",
    "\n",
    "* F<sub>1</sub> score is calculated as two times the number of true positives divided by two times the number of true positives plus the number of false positives and false negatives (F1_Score, n.d.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a medical context, there are pros and cons to the above metrics. Focusing on precision would minimize the number of false positives, reducing the need for unnecessary resources. On the other hand, prioritizing recall would minimize false negatives, allowing the model to correctly identify as many diabetic individuals as possible. The F<sub>1</sub> score combines both recall and precision, offering a balanced view of performance.\n",
    "\n",
    "Since both false positives and false negatives have significant consequences in medical predictions, the F<sub>1</sub> score will be the focal point of this evaluation. By balancing precision and recall, the F<sub>1</sub> score ensures that the model performs well across both metrics, making it a more comprehensive measure of its effectiveness in predicting diabetic individuals while minimizing potential risks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train test split function\n",
    "from sklearn.model_selection import  train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating separate diabetes status variable, and deleting diabetes status variable from original dataset.\n",
    "df_target = df['diabetes_status']\n",
    "del df['diabetes_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up the data set into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df_target, test_size=0.30, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing preprocessing functions. \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating initial pipeline.\n",
    "pipe1 = Pipeline([\n",
    "    ('log', FunctionTransformer(func=np.log1p)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "# Creating list for all continuous and discrete variables.\n",
    "cont = ['age','height_inches','bmi']\n",
    "disc = ['general_health', 'physical_health_days', 'mental_health_days',\n",
    "       'has_health_plan', 'meets_aerobic_guidelines',\n",
    "       'physical_activity_150min', 'muscle_strengthening',\n",
    "       'high_blood_pressure', 'high_cholesterol', 'heart_disease',\n",
    "       'lifetime_asthma', 'arthritis', 'sex', \n",
    "       'education_level', 'income_group', 'smoking_status',\n",
    "       'alcohol_consumption', 'binge_drinking', 'heavy_drinking',\n",
    "       'difficulty_walking']\n",
    "\n",
    "# Creating column transformer to send all continuous variables to pipe1 and scale all the discrete variables. \n",
    "ct = ColumnTransformer([\n",
    "    ('num', pipe1, cont),\n",
    "    ('disc', StandardScaler(), disc),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting ct with the training predictors, transforming the training predictors using ct, and transforming the testing predictors with ct.\n",
    "X_train1 = ct.fit_transform(X_train)\n",
    "X_test1 = ct.transform(X_test)\n",
    "\n",
    "# Creating data sets with newly transformed predictor data.\n",
    "X_train1 = pd.DataFrame(X_train1, columns=X_train.columns)\n",
    "X_test1 = pd.DataFrame(X_test1, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Predictor Training Set: (152586, 23)\n",
      "Dimensions of Predictor Testing Set: (65395, 23)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions of Predictor Training Set:', X_train1.shape)\n",
    "print('Dimensions of Predictor Testing Set:', X_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing f1_score function.\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Logistic Regression function\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training data: 0.28\n",
      "f1_score on testing data: 0.28\n"
     ]
    }
   ],
   "source": [
    "# Creating Logistic Regression model.\n",
    "lg = LogisticRegression()\n",
    "\n",
    "# Fitting lg with training data.\n",
    "lg.fit(X_train1, y_train)\n",
    "\n",
    "# Calculating the f1_score on the training data for lg.\n",
    "pred_target = lg.predict(X_train1)\n",
    "f1_train = np.round(f1_score(y_train, pred_target),2)\n",
    "print('f1_score on training data:', f1_train)\n",
    "\n",
    "# Calculating the f1_score on the testing data for lg.\n",
    "pred_target = lg.predict(X_test1)\n",
    "f1_test = np.round(f1_score(y_test, pred_target),2)\n",
    "print('f1_score on testing data:', f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't a great start, but since this is a fairly basic model with little parameter tinkering, it is a start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training data: 0.46\n",
      "f1_score on testing data: 0.46\n"
     ]
    }
   ],
   "source": [
    "# Creating LogisticRegression model with class_weight set to balanced.\n",
    "lg = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Fitting lg with training data.\n",
    "lg.fit(X_train1, y_train)\n",
    "\n",
    "# Calculating f1_score on training data.\n",
    "pred_target = lg.predict(X_train1)\n",
    "f1_train = np.round(f1_score(y_train, pred_target),2)\n",
    "print('f1_score on training data:', f1_train)\n",
    "\n",
    "# Calculating f1_score on testing data. \n",
    "pred_target = lg.predict(X_test1)\n",
    "f1_test = np.round(f1_score(y_test, pred_target),2)\n",
    "print('f1_score on testing data:', f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tinkering with the class_weight parameter, we were able to increase the f1_score of the model by .18 for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing grid search cv function, stratified fold function for cv, and make scorer function for custom scoring metric\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 0.5],\n",
       "                         &#x27;class_weight&#x27;: [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}, {0: 1, 1: 5.69}]},\n",
       "             scoring=make_scorer(f1_score, pos_label=1), verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 0.5],\n",
       "                         &#x27;class_weight&#x27;: [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}, {0: 1, 1: 5.69}]},\n",
       "             scoring=make_scorer(f1_score, pos_label=1), verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 0.5],\n",
       "                         'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}, {0: 1, 1: 5.69}]},\n",
       "             scoring=make_scorer(f1_score, pos_label=1), verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dictionary for different parameter possibilities. \n",
    "param_dist = {\n",
    "    'C': [0.001, .01, .1, .5],\n",
    "    'class_weight': [{0: 1, 1: w} for w in [1, 2, 3, 5.69]]\n",
    "}\n",
    "\n",
    "#  Specifying initial Logistic Regression model.\n",
    "lg = LogisticRegression(random_state=42)\n",
    "# Creating custom scoring metric.\n",
    "f1 = make_scorer(f1_score, pos_label=1)\n",
    "# Creating GridSearchCV function.\n",
    "grid = GridSearchCV(lg, param_dist, cv=StratifiedKFold(n_splits=4), scoring = f1, verbose=1)\n",
    "# Fitting grid with the training data.\n",
    "grid.fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'class_weight': {0: 1, 1: 3}}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training data: 0.47\n",
      "f1_score on testing data: 0.47\n"
     ]
    }
   ],
   "source": [
    "lg = grid.best_estimator_\n",
    "lg.fit(X_train1, y_train)\n",
    "pred_target = lg.predict(X_train1)\n",
    "f1_train = np.round(f1_score(y_train, pred_target),2)\n",
    "print('f1_score on training data:', f1_train)\n",
    "pred_target = lg.predict(X_test1)\n",
    "f1_test = np.round(f1_score(y_test, pred_target),2)\n",
    "print('f1_score on testing data:', f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I thought maybe there would be more of an increase with our model, we can tell that the f1_score on the testing data only increased by .01. In other words, we could flip a coin, and get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Random Forest Classifier function.\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training data: 1.0\n",
      "f1_score on testing data: 0.26\n"
     ]
    }
   ],
   "source": [
    "# Creating Random Forest Classifier model with random state set to 42 for reproducibility.\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fitting rfc with training data. \n",
    "rfc.fit(X_train1, y_train)\n",
    "\n",
    "# Calculating the f1_score on the training data for rfc.\n",
    "pred_target = rfc.predict(X_train1)\n",
    "f1_train = f1_score(y_train, pred_target, pos_label=1)\n",
    "print('f1_score on training data:', np.round(f1_train,2))\n",
    "\n",
    "# Calculating the f1_score on the testing data for rfc.\n",
    "pred_target = rfc.predict(X_test1)\n",
    "f1_test = f1_score(y_test, pred_target, pos_label=1)\n",
    "print('f1_score on testing data:', np.round(f1_test,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting is present with drastic drop in f1_score for testing data compared to training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training data: 1.0\n",
      "f1_score on testing data: 0.23\n"
     ]
    }
   ],
   "source": [
    "# Creating random forest classifier with random state and class_weight set to balanced.\n",
    "rfc = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Fitting rfc with training data. \n",
    "rfc.fit(X_train1, y_train)\n",
    "\n",
    "# Calculating f1_score on training data for rfc.\n",
    "pred_target = rfc.predict(X_train1)\n",
    "f1_train = f1_score(y_train, pred_target, pos_label=1)\n",
    "print('f1_score on training data:', np.round(f1_train,2))\n",
    "\n",
    "# Calculating f1_Score on testing data for rfc.\n",
    "pred_target = rfc.predict(X_test1)\n",
    "f1_test = f1_score(y_test, pred_target, pos_label=1)\n",
    "print('f1_score on testing data:', np.round(f1_test,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tinkering with the class_weight parameter made the testing f1_score worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "                   estimator=RandomForestClassifier(random_state=22),\n",
       "                   param_distributions=[{&#x27;class_weight&#x27;: [{0: 1, 1: 1},\n",
       "                                                          {0: 1, 1: 3},\n",
       "                                                          {0: 1, 1: 5.69},\n",
       "                                                          None],\n",
       "                                         &#x27;max_depth&#x27;: [5, 10],\n",
       "                                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                         &#x27;n_estimators&#x27;: [10, 30, 100]}],\n",
       "                   random_state=42, scoring=make_scorer(f1_score, pos_label=1),\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "                   estimator=RandomForestClassifier(random_state=22),\n",
       "                   param_distributions=[{&#x27;class_weight&#x27;: [{0: 1, 1: 1},\n",
       "                                                          {0: 1, 1: 3},\n",
       "                                                          {0: 1, 1: 5.69},\n",
       "                                                          None],\n",
       "                                         &#x27;max_depth&#x27;: [5, 10],\n",
       "                                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                         &#x27;n_estimators&#x27;: [10, 30, 100]}],\n",
       "                   random_state=42, scoring=make_scorer(f1_score, pos_label=1),\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=22)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "                   estimator=RandomForestClassifier(random_state=22),\n",
       "                   param_distributions=[{'class_weight': [{0: 1, 1: 1},\n",
       "                                                          {0: 1, 1: 3},\n",
       "                                                          {0: 1, 1: 5.69},\n",
       "                                                          None],\n",
       "                                         'max_depth': [5, 10],\n",
       "                                         'max_features': ['sqrt', 'log2'],\n",
       "                                         'n_estimators': [10, 30, 100]}],\n",
       "                   random_state=42, scoring=make_scorer(f1_score, pos_label=1),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = [{\n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'max_depth': [5, 10],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'class_weight': [{0:1, 1:w} for w in [1, 3, 5.69]] + [None]\n",
    "}]\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=22)\n",
    "\n",
    "# Creating custom scoring metric.\n",
    "f1 = make_scorer(f1_score, pos_label=1)\n",
    "# Creating GridSearchCV function.\n",
    "grid = RandomizedSearchCV(rfc, param_dist, cv=StratifiedKFold(n_splits=4), scoring = f1, verbose=1, random_state=42)\n",
    "# Fitting grid with the training data.\n",
    "grid.fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 30, 'max_features': 'sqrt', 'max_depth': 10, 'class_weight': {0: 1, 1: 3}}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training data: 0.51\n",
      "f1_score on testing data: 0.46\n"
     ]
    }
   ],
   "source": [
    "# Creating random forest classifier from the best estimator from rand_search.\n",
    "rfc = grid.best_estimator_\n",
    "\n",
    "# Fitting rfc with training data.\n",
    "rfc.fit(X_train1, y_train)\n",
    "\n",
    "# Calculating f1_score on training data for rfc\n",
    "pred_target = rfc.predict(X_train1)\n",
    "f1_train = f1_score(y_train, pred_target, pos_label=1)\n",
    "print('f1_score on training data:', np.round(f1_train,2))\n",
    "\n",
    "# Calculating f1_score on testing data for rfc.\n",
    "pred_target = rfc.predict(X_test1)\n",
    "f1_test = f1_score(y_test, pred_target, pos_label=1)\n",
    "print('f1_score on testing data:', np.round(f1_test,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't as much difference between training and testing f1_scores, but testing f1_score is still not great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic HistGradBoostingClassifier\n",
      "f1_score on training data: 0.29\n",
      "f1_score on testing data: 0.28\n",
      "\n",
      "HistGradientBoostingClassifier with class weight set to balanced.\n",
      "f1_score on training data: 0.47\n",
      "f1_score on testing data: 0.46\n"
     ]
    }
   ],
   "source": [
    "# Creating HistGradientBoostingClassifier with random state for reproducibility.\n",
    "hbc = HistGradientBoostingClassifier(random_state=22)\n",
    "\n",
    "# Fitting hbc with training data.\n",
    "hbc.fit(X_train1, y_train)\n",
    "\n",
    "# Calculating f1_score on training data for hbc.\n",
    "pred_target = hbc.predict(X_train1)\n",
    "f1_train = f1_score(y_train, pred_target, pos_label=1)\n",
    "print('Basic HistGradBoostingClassifier')\n",
    "print('f1_score on training data:', np.round(f1_train,2))\n",
    "\n",
    "# Calculating f1_score on testing data for hbc.\n",
    "pred_target = hbc.predict(X_test1)\n",
    "f1_test = f1_score(y_test, pred_target, pos_label=1)\n",
    "print('f1_score on testing data:', np.round(f1_test,2))\n",
    "\n",
    "print()\n",
    "\n",
    "# Creating HistGradientBoostingClassifier with random state and class weight set to balanced.\n",
    "hbc = HistGradientBoostingClassifier(random_state=22, class_weight='balanced')\n",
    "\n",
    "# Fitting hbc with training data.\n",
    "hbc.fit(X_train1, y_train)\n",
    "\n",
    "# Calculating f1_score on training data for hbc.\n",
    "pred_target = hbc.predict(X_train1)\n",
    "f1_train = f1_score(y_train, pred_target, pos_label=1)\n",
    "print('HistGradientBoostingClassifier with class weight set to balanced.')\n",
    "print('f1_score on training data:', np.round(f1_train,2))\n",
    "\n",
    "# Calculating f1_score on testing data for hbc.\n",
    "pred_target = hbc.predict(X_test1)\n",
    "f1_test = f1_score(y_test, pred_target, pos_label=1)\n",
    "print('f1_score on testing data:', np.round(f1_test,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model doesn't have the overfitting that the random forest classifier had. Like the logistic regression model, we were able to increase the f1_score by setting class weight to balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "HistGradientBoostingClassifier(class_weight={0: 1, 1: 3},\n",
      "                               l2_regularization=0.25, max_depth=20,\n",
      "                               max_leaf_nodes=5, min_samples_leaf=10,\n",
      "                               random_state=22)\n",
      "0.4763985799866082\n"
     ]
    }
   ],
   "source": [
    "param_dist = [{\n",
    "    'learning_rate': [.1, .5, .9],\n",
    "    'max_iter': [10, 50, 100],\n",
    "    'max_leaf_nodes': [5, 15],\n",
    "    'max_depth': [5,10,20],\n",
    "    'min_samples_leaf': [5,10],\n",
    "    'l2_regularization': [.1, .25, 1],\n",
    "    'class_weight': [{0:1, 1:w} for w in [1, 3, 5.69]]\n",
    "\n",
    "}]\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "hgbc = HistGradientBoostingClassifier(random_state=22)\n",
    "\n",
    "rand_search = RandomizedSearchCV(hgbc, param_distributions=param_dist, \n",
    "                                scoring=f1_scorer, cv=StratifiedKFold(n_splits=4), verbose=1, n_iter=50, random_state=22)\n",
    "\n",
    "rand_search.fit(X_train1, y_train)\n",
    "\n",
    "print(rand_search.best_estimator_)\n",
    "print(rand_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training data: 0.48\n",
      "f1_score on testing data: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Creating HistGradientBoostingClassifier based on best estimator from rand_search.\n",
    "hbc = rand_search.best_estimator_\n",
    "\n",
    "# Fitting hbc with training data.\n",
    "hbc.fit(X_train1, y_train)\n",
    "\n",
    "# Calculating f1_score on training data for hbc.\n",
    "pred_target = hbc.predict(X_train1)\n",
    "f1_train = f1_score(y_train, pred_target, pos_label=1)\n",
    "print('f1_score on training data:', np.round(f1_train,2))\n",
    "\n",
    "# Calculating f1_score on testing data for hbc.\n",
    "pred_target = hbc.predict(X_test1)\n",
    "f1_test = f1_score(y_test, pred_target, pos_label=1)\n",
    "print('f1_score on testing data:', np.round(f1_test,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did find a new high f1_score for the model, but it still isn't great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I eventually want to explore more complex models such as XGBoost and neural networks, I recognize that my current approach isn't necessarily flawed, but it may not be entirely correct. For instance, one-hot encoding discrete variables might prove more helpful. However, this would significantly increase the dimensionality of the training and testing datasets, so analyzing feature importance or reducing dimensionality could be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* precision_score. (n.d.). Scikit-learn. https://scikit-learn.org/dev/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score\n",
    "\n",
    "* recall_score. (n.d.). Scikit-learn. https://scikit-learn.org/dev/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score\n",
    "\n",
    "* f1_score. (n.d.). Scikit-learn. https://scikit-learn.org/dev/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
