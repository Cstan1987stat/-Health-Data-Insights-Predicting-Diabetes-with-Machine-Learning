# Health Data Insights Project

## Project Overview
This project utilizes machine learning techniques to predict diabetes status based on health and behavioral data from the CDC’s Behavioral Risk Factor Surveillance System (BRFSS) survey. By analyzing factors such as physical activity and BMI, the model aims to identify individuals at risk for diabetes, providing insights that could aid in early detection and intervention.

## Completed Work
* **[Initial Notebook](https://github.com/Cstan1987stat/-Health-Data-Insights-Predicting-Diabetes-with-Machine-Learning/blob/main/notebooks/inital%20notebook.ipynb)** : This notebook outlines how the dataset was obtained, explains the features and their values, and details the process of selecting relevant variables. It also includes filtering and transforming feature values, renaming columns, and conducting basic exploratory data analysis on both continuous and discrete features.
* **[First Model Buidling Process](https://github.com/Cstan1987stat/-Health-Data-Insights-Predicting-Diabetes-with-Machine-Learning/blob/main/notebooks/first%20model%20building%20process.ipynb)** Applied preprocessing by log-transforming and standard scaling continuous features, and standard scaling discrete features. Trained Logistic Regression, Random Forest, and Histogram-based Gradient Boosting Classifier models. Improved the Logistic Regression model’s F1-score from 0.28 to 0.46 by adjusting the class_weight parameter. Used RandomizedSearchCV to tune hyperparameters and achieved an F1-score of 0.48 with the Histogram-based Gradient Boosting Classifier on both training and testing sets.
* **[A Second Attempt](https://github.com/Cstan1987stat/-Health-Data-Insights-Predicting-Diabetes-with-Machine-Learning/blob/main/notebooks/a%20second%20attempt.ipynb)** : Changed the preprocessing pipeline by log-transforming and scaling continuous features, and one-hot encoding discrete features. Tuned Logistic Regression, Random Forest, Histogram-based Gradient Boosting, and XGBoost models. Despite efforts, the highest F1-score achieved remained at 0.48.
* **[Analyzing the Scoring](https://github.com/Cstan1987stat/-Health-Data-Insights-Predicting-Diabetes-with-Machine-Learning/blob/main/notebooks/analyzing%20the%20scoring.ipynb)** : Evaluated model performance using confusion matrices for both Histogram-based Gradient Boosting and XGBoost models. Experimented with adjusting probability thresholds for classification and applied SMOTE to address class imbalance. Neither threshold tuning nor SMOTE led to significant improvements; SMOTE, in particular, caused the model to overfit and perform poorly on test data.
* **[A Fourth Attempt](https://github.com/Cstan1987stat/-Health-Data-Insights-Predicting-Diabetes-with-Machine-Learning/blob/main/notebooks/a_fourth_attempt.ipynb)** : Revised the preprocessing strategy by splitting discrete features into ordinal and nominal categories. Tuned a Logistic Regression model and evaluated performance on the test set. Successfully exported the final trained model and the corresponding column transformer using joblib, which were later deployed in a **[Streamlit App](https://diabetic-prediction-app-4321.streamlit.app/)**.

The page for the code to create the streamlit app can be found here: **[GitHub Streamlit App Page](https://github.com/Cstan1987stat/Diabetic-Prediction-App-Site)**.

## Conclusion

